% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_performance.R
\name{compute_performance}
\alias{compute_performance}
\alias{print.mscraw}
\alias{points.mscraw}
\alias{lines.mscraw}
\title{Computes performance measures for prognostic scores on a set of bootstrap samples}
\usage{
compute_performance(bs.sample, fn = calibration_slope, lbl = NULL)

\method{print}{mscraw}(x, ...)

\method{points}{mscraw}(x, ...)

\method{lines}{mscraw}(x, ...)
}
\arguments{
\item{bs.sample}{A set of cohort-stratified bootstrap samples, as generated with \code{\link{get_bs_samples}}}

\item{fn}{The name of a function to compute performance measures. For example, \code{\link{calibration_slope}}. See \strong{details}.}

\item{lbl}{A label to describe the performance measure computed. For example \code{"calibration slope"}. This label is used in subsequent plot functions, and appears in tables of regression coefficients of. Useful if you want to compute several performance measures, or the same performance measure on different subsets of data.}

\item{x}{Set of performance estimates calculated with \code{\link{compute_performance}}}

\item{...}{Other arguments to be passed to \code{\link{print}}. Ignored by summary, points and lines.}
}
\value{
A list with 3 elements, of class \code{msc_raw}:
\describe{
  \item{working.estimates}{A tibble containing a set of "working estimates", the raw performance measures, before they have been aggregated or contrasts have been computed.}
  \item{scores}{Names of the scores as given in \code{\link{get_bs_samples}}}
  \item{formulas}{vector of formulas)}
  \item{fn}{The function definition used to compute performance}
  \item{lbl}{The label given in the arguments.}
}
The results of \code{\link{compute_performance}} have suitable \code{print} and \code{summary} methods.
}
\description{
Computes performance measures for prognostic scores on a set of bootstrap samples

#' @describeIn compute_performance Print summary of raw performance estimates
#' @param object Set of performance estimates calculated with \code{\link{compute_performance}}
#' @param nonpar  Should nonparametric summary statistics (median [IQR]) be reported? (TRUE)
#' @param NArm Should NAs be removed before calculated summary statistics? (TRUE)
#' @export
summary.mscraw <- function(object, nonpar = TRUE, NArm = TRUE, ...){
  sc <- object$scores
  object.apparent <- object$working.estimates %>%
    filter(id == "Apparent") %>%
    select(.data$cohort, sc)
  q1 <- partial(quantile, probs = 0.25, na.rm = NArm)
  q3 <- partial(quantile, probs = 0.75, na.rm = NArm)
  nonmiss <- function(object) sum(!is.na(object))
  if(nonpar){
    fns <- list("nonmiss" = nonmiss, "median" = partial(median, na.rm = NArm), 
                "q1" = q1, "q3" = q3)
  } else {
    fns <- list("nonmiss" = nonmiss, "mean" = partial(mean, na.rm = NArm), 
                "sd" = partial(sd, na.rm = NArm))
  }
  object.apparent  %>%
    gather(sc, key = "score", value = "value") %>%
    group_by(.data$score) %>%
    summarize_at("value", fns) %>%
    mutate(performance = object$lbl) %>%
    select(.data$score, .data$performance, everything())
}
}
\details{
The function to compute performance measures, \code{fn} requires two arguments:
\describe{ 
\item{bss}{The name of the bootstrap sample. The full bootstrap data is called within the function as \code{analysis(bss)}. See  \code{\link[rsample]{bootstraps}} for more details.}
  \item{fn}{The formula that will be called by the model, of the form \code{outcome ~ score} (character).}
}
and outputs a single numeric value. Using \code{\link{possibly}}, \code{\link{compute_performance}} assigns a value of \code{NA} if there is an error.
}
\section{Methods (by generic)}{
\itemize{
\item \code{print}: Print raw performance estimates

\item \code{points}: Plot variability of raw performance estimates across bootstrap samples using points

\item \code{lines}: Plot variability of raw performance estimates across bootstrap samples using lines (density plots)
}}

\examples{
dat <- msc_sample_data()
bssamp <- get_bs_samples(dat, id, study, outcome, n.samples = 5, 
                  scores = c("a", "b", "c", "d", "e", "f"), 
                  moderators = c("age", "female", "x1"))
perf <- compute_performance(bssamp, fn = calibration_slope, lbl = "CS")
print(perf)
summary(perf)
points(perf)
lines(perf)
}
