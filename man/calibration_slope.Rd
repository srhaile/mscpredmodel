% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calibration_slope.R
\name{calibration_slope}
\alias{calibration_slope}
\alias{calibration_large}
\alias{c_statistic}
\alias{oe_ratio}
\alias{brier_score}
\alias{int_calib_index}
\alias{ICI}
\alias{E50}
\alias{E90}
\alias{Emax}
\title{Compute performance in terms of various typical calibration and discrimination measures.}
\usage{
calibration_slope(obs, pred)

calibration_large(obs, pred)

c_statistic(obs, pred)

oe_ratio(obs, pred)

brier_score(obs, pred)

int_calib_index(obs, pred)

E50(obs, pred)

E90(obs, pred)

Emax(obs, pred)
}
\arguments{
\item{obs}{A vector of observed scores}

\item{pred}{A vector of observed outcomes}
}
\value{
A single performance measure (numeric).
}
\description{
Here we provide several functions to compute some typical performance measures for calibration and discrimination (calibration slope, calibration-in-the-large, c-Statistic / AUC, O:E ratio, Brier score, integrated calibration index, and related E50, E90, and Emax). This is not intended to be an exhaustive set of performance measures.
}
\details{
In some cases, it may be better to perform network meta-analysis on transformed performance measures, for example log calibration slope or logit AUC, as these may be closer to normally distributed. The examples below show how these could be computed.
}
\section{Functions}{
\itemize{
\item \code{calibration_slope()}: Estimate calibration slope

\item \code{calibration_large()}: Estimate calibration-in-the-large

\item \code{c_statistic()}: Estimate c-Statistic / Area under the ROC curve

\item \code{oe_ratio()}: Estimate ratio of observed to expected number of events

\item \code{brier_score()}: Estimate Brier score

\item \code{int_calib_index()}: Estimate Integrated Calibration Index (ICI) (mean)

\item \code{E50()}: Estimate Integrated Calibration Index (ICI) (median)

\item \code{E90()}: Estimate Integrated Calibration Index (ICI) (90th percentile)

\item \code{Emax()}: Estimate Integrated Calibration Index (ICI) (maximum)

}}
\examples{
n <- 100
predscore <- runif(n)
outcome <- as.numeric(rnorm(n, predscore) > 1)

# using a built-in function
calibration_slope(outcome, predscore)


# adapt above to compute log calibration slope
log_cs <- function(obs, pred){
    log(calibration_slope(obs, pred))
}
log_cs(outcome, predscore)

# or adapt c_statistic to get logit AUC
logit_auc <- function(obs, pred){
qlogis(c_statistic(obs, pred))
} 
logit_auc(outcome, predscore)
}
\seealso{
Austin, PC, Steyerberg, EW. The Integrated Calibration Index (ICI) and related metrics for quantifying the calibration of logistic regression models. Statistics in Medicine. 2019; 1– 15. https://doi.org/10.1002/sim.8281

Debray, T. P., Damen, J. A., Riley, R. D., Snell, K., Reitsma, J. B., Hooft, L., … Moons, K. G. (2018). A framework for meta-analysis of prediction model studies with binary and time-to-event outcomes. Statistical Methods in Medical Research. https://doi.org/10.1177/0962280218785504

Snell KI, Ensor J, Debray TP, et al (2017). Meta-analysis of prediction model performance across multiple studies: which scale helps ensure between-study normality for the C -statistic and calibration measures? Statistical Methods in Medical Research. https://doi.org/10.1177/0962280217705678
}
